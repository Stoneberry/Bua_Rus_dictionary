{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUSCORPORA BUA PARSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Подготовили - Анастасия Костяницына, Артем Копецкий\n",
    "\n",
    "* Парсинг параллельного бурятского корпуса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from lxml import etree\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура данных для примеров из НКРЯ (text_bua - бурятские примеры, text_rus - русские примеры)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pair:\n",
    "    \n",
    "    def __init__(self, id_, bua, rus):\n",
    "        self.id_ = id_\n",
    "        self.tokens_bua, self.infos_bua = bua\n",
    "        self.tokens_rus, self.infos_rus = rus\n",
    "        \n",
    "        self.text_bua = ''.join(self.tokens_bua).strip()\n",
    "        self.text_rus = ''.join(self.tokens_rus).strip()\n",
    "        \n",
    "    def find_rus_in_bua(self, word):\n",
    "        res = []\n",
    "        \n",
    "        for token, info in zip(self.tokens_bua, self.infos_bua):\n",
    "            _info = info.get('sem')\n",
    "            \n",
    "            if _info is not None and word in _info:\n",
    "                res.append((word, token, info))\n",
    "                \n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infos_dict(word):\n",
    "    return {info: [x.text.strip(punctuation) for x in word.xpath(XPATH_TO_INFO % info)] for info in INFOS}\n",
    "\n",
    "\n",
    "def parse_doc(doc):\n",
    "    tokens = []\n",
    "    infos = []\n",
    "    \n",
    "    \n",
    "    for el in doc.getchildren():\n",
    "     \n",
    "        if el.tag == 'text':\n",
    "            tokens.append(el.text)\n",
    "            infos.append({})\n",
    "            \n",
    "        else:\n",
    "            tokens.append(el.attrib['text'])\n",
    "            infos.append(get_infos_dict(el))\n",
    "            \n",
    "    return tokens, infos\n",
    "\n",
    "\n",
    "def parse_page(url):\n",
    "    \n",
    "    tree = etree.parse(url)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    all_ = []\n",
    "    \n",
    "    for doc1 in root.xpath(XPATH_TO_DOC):\n",
    "        \n",
    "        d = {}\n",
    "        pairs_parsed = []\n",
    "        \n",
    "        for child in doc1:\n",
    "            \n",
    "            if child.tag == 'attributes':\n",
    "                for i in child:\n",
    "                    d[i.attrib['name']] = i.attrib['value']\n",
    "            \n",
    "            if child.tag == 'para':\n",
    "                \n",
    "                doc1 = child[0]\n",
    "                doc2 = child[1]\n",
    "        \n",
    "                if doc1.attrib['sid'] == doc2.attrib['sid']:\n",
    "                    if doc1.attrib['language'] == 'bua':\n",
    "                        pairs_parsed.append(Pair(doc1.attrib['sid'], parse_doc(doc1), parse_doc(doc2)))\n",
    "                    else:\n",
    "                        pairs_parsed.append(Pair(doc1.attrib['sid'], parse_doc(doc2), parse_doc(doc1)))\n",
    "               \n",
    "        #d['pairs'] = pairs_parsed\n",
    "        all_.append((d, pairs_parsed))\n",
    "        \n",
    "    return all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPATH_TO_DOC = 'searchresult/body/result/document'\n",
    "XPATH_TO_PAIRS = 'searchresult/body/result/document/para' \n",
    "XPATH_TO_INFO = 'ana/el[@name=\"%s\"]/el-group/el-atom'\n",
    "INFOS = ('lex', 'gramm', 'sem', 'flags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = 'http://search1.ruscorpora.ru/dump.xml?mysent=&mysize=273016&mysentsize=6674&dpp=&spp=&spd=&text=lexgramm&mode=para&sort=gr_tagging&env=alpha&mycorp=%28lang%3A\"bua\"+%7C+lang_trans%3A\"bua\"%29&parent1=0&level1=0&lex1={}&gramm1=&flags1=&sem1=&parent2=0&level2=0&min1=1&max1=1&lex2=&gramm2=&flags2=&sem2='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грамм. запрос \"отец\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = url_template.format('отец')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 156 ms, sys: 15.6 ms, total: 172 ms\n",
      "Wall time: 517 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = parse_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://search1.ruscorpora.ru/dump.xml?mysent=&mysize=273016&mysentsize=6674&dpp=&spp=&spd=&text=lexgramm&mode=para&sort=gr_tagging&env=alpha&mycorp=%28lang%3A\"bua\"+%7C+lang_trans%3A\"bua\"%29&parent1=0&level1=0&lex1=отец&gramm1=&flags1=&sem1=&parent2=0&level2=0&min1=1&max1=1&lex2=&gramm2=&flags2=&sem2='"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основная часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bua_words.txt', 'r') as f:\n",
    "    WORDS = [x.rstrip('\\n') for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from time import sleep\n",
    "from random import randint, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_PAIRS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1533c4183448de8d89b8b2981c3248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1114), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, w in enumerate(tqdm_notebook(WORDS)):\n",
    "    url = url_template.format(w)\n",
    "    \n",
    "    try:\n",
    "        WORDS_PAIRS[w] = parse_page(url)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if random() < 0.2:\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_status(match):\n",
    "    \"\"\"\n",
    "    match: i-th el of `.find_rus_in_bua` output\n",
    "    \"\"\"\n",
    "    \n",
    "    infos = match[-1]\n",
    "    \n",
    "    lex = infos.get('lex') or []\n",
    "    \n",
    "    # deny if more than one bua lexeme \n",
    "    if len(lex) > 1:\n",
    "        return 2\n",
    "    \n",
    "    gramm = infos.get('gramm') or []\n",
    "    \n",
    "    # mark if more than one gramm info\n",
    "    if len([_ for x in gramm if x.isupper()]) > 1:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_matches(words_pairs):\n",
    "    matches = defaultdict(list)\n",
    "    \n",
    "    for word, data in words_pairs.items():\n",
    "        for doc, pairs in data:\n",
    "            for pair in pairs:\n",
    "                c_matches = pair.find_rus_in_bua(word)\n",
    "                matches[word].extend(\n",
    "                    [{'status': get_match_status(m), 'doc': doc, 'pair': pair, 'match': m[1:]}\n",
    "                     for m in c_matches\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 688 ms, sys: 281 ms, total: 969 ms\n",
      "Wall time: 984 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "matches = get_matches(WORDS_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bua_rus_matches.pkl', 'wb') as f:\n",
    "    pickle.dump(matches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bua_rus_matches.pkl', 'rb') as f:\n",
    "    matches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура данных для словарной статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entry:\n",
    "    \n",
    "    def __init__(self, lex):\n",
    "        self.lex = lex\n",
    "        \n",
    "        self.pos = {}\n",
    "        self.sem = {}\n",
    "        self.gramm = {}\n",
    "        self.examples = defaultdict(list)\n",
    "        \n",
    "    def add_pos(self, pos):\n",
    "        if pos not in self.pos:\n",
    "            self.pos[pos] = {}\n",
    "    \n",
    "    def add_sem(self, pos, sem):\n",
    "        if sem not in self.pos[pos]:\n",
    "            self.pos[pos][sem] = {}\n",
    "    \n",
    "    def add_form(self, pos, sem, gramm, form):\n",
    "        if gramm not in self.pos[pos][sem]:\n",
    "            self.pos[pos][sem][gramm] = form\n",
    "            \n",
    "    def add_example(self, sem, doc, pair):\n",
    "        self.examples[sem].append((doc, pair))\n",
    "            \n",
    "    def get_tree(self):\n",
    "        return self.pos\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаем из примеров из НКРЯ сочетания слов и грамматической информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_gramms(gramm_info):\n",
    "    res = []\n",
    "    c_info = gramm_info[:1]\n",
    "\n",
    "    for x in gramm_info[1:]:\n",
    "        if not x.isupper():\n",
    "            c_info.append(x)\n",
    "\n",
    "        else:\n",
    "            res.append(c_info)\n",
    "            c_info = [x]\n",
    "\n",
    "    res.append(c_info)\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "def build_entries_from_matches(matches):\n",
    "    entries = {}\n",
    "    \n",
    "    for word, c_matches in matches.items():\n",
    "        c_entries = {}\n",
    "        \n",
    "        for match in c_matches:\n",
    "            c_status = match['status']\n",
    "            \n",
    "            # ambiguous case: multiple lexemes\n",
    "            if c_status == 2:\n",
    "                continue\n",
    "                \n",
    "            form, info = match['match']\n",
    "            lex = info['lex'][0]\n",
    "            \n",
    "            if lex not in c_entries:\n",
    "                c_entries[lex] = Entry(lex)\n",
    "\n",
    "            entry = c_entries[lex]\n",
    "            \n",
    "            # unambiguous case: single lexeme, single gramm\n",
    "            if c_status == 0:\n",
    "                pos = info['gramm'][0]\n",
    "                gramm = ', '.join(info['gramm'][1:])\n",
    "                sem = ', '.join(info['sem'])\n",
    "\n",
    "                entry.add_pos(pos)\n",
    "                entry.add_sem(pos, sem)\n",
    "                entry.add_form(pos, sem, gramm, form.lower())\n",
    "                entry.add_example(sem, match['doc'], match['pair'])\n",
    "            \n",
    "            # semi-ambiguous case: single lexeme, multiple gramms\n",
    "            else:\n",
    "                gramms = get_all_gramms(info['gramm'])\n",
    "                sems = [', '.join(info['sem'])] + ['AMBIGUOUS'] * (len(gramms) - 1)\n",
    "                \n",
    "                for gramm, sem in zip(gramms, sems):\n",
    "                    pos = gramm[0]\n",
    "                    _gramm = ', '.join(gramm[1:])\n",
    "                    \n",
    "                    entry.add_pos(pos)\n",
    "                    entry.add_sem(pos, sem)\n",
    "                    entry.add_form(pos, sem, _gramm, form.lower())\n",
    "                    entry.add_example(sem, match['doc'], match['pair'])\n",
    "                    \n",
    "        entries[word] = c_entries\n",
    "        \n",
    "    return entries\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 15.6 ms, total: 46.9 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entries = build_entries_from_matches(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bua_rus_entries.pkl', 'wb') as f:\n",
    "    pickle.dump(entries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bua_rus_entries.pkl', 'rb') as f:\n",
    "    entries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем все вхождения Отца в нашей базе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('отец', 'Эсэгынгээ', {'lex': ['эсэгэ'], 'gramm': ['S', 'gen', 'poss'], 'sem': ['отец'], 'flags': ['bua', 'capital', 'first', 'nacc', 'posred']})]\n",
      "Эсэгынгээ хэрэгээр Үдын байшан ошоһон аад, орой гэртээ хүрэжэ ерээ һэм, — гэжэ Бадан мүн лэ илдамаар харюусаад, урдаһаань баһа нэнгэжэ, ургынгаа гуйба мүртөө шагтагалһан баруун гараараа морин дээрэһээ Залмые хүзүүдэн, даараһандаа улайхадаһан хасартань өөрынгөө хасар няаба.\n",
      "— Отец отправил в Удинский острог, вернулся поздно. Не сердись, если не острог, обязательно приехал бы.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'casered', 'nacc', 'posred']})]\n",
      "— Манай адуун.    Минии эсэгэ Жарантай хоёрой.    — Аа, мүнөө эдэ адуунтнай манай болоо.\n",
      "— Наш.    Моего отца и Жарантая,    — Теперь это наш табун.\n",
      "\n",
      "[]\n",
      "— Тураахиин хүбүүн Бадан гэжэ аабза.    Тэрэшни эсэгэдээл адли ород эльгэтэй, саашаа һанаатай амитан байха.    Тэрэ Тураахиһаа боложо, буряадууд манда алба татабари түлэхэеэ болёо бшуу.\n",
      "Сын Туракая, как его, Бадан, кажется?    Такой же непокорный, как и отец.    Из-за этого Туракая буряты отказались платить мне дань, стали переходить к русским.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc', 'posred']})]\n",
      "Тиибэшье тэрэнэй эсэгэ, үбгэн Тураахи ноён, хүсэд эдэгэтэрээ ород эмшэндэ аргалуулжа, байшанда байгаа хадань дээрэ гэжэ бодоһон юм. Гэр бүлөөрөө, түшэмэд сэлтэнэрээрээ Түгнын голдо нютаглажа һууһанаа, хүбүүндээ дүтэлжэ, Үдын гол худар зөөһэн юм. Тиимэһээ хүбүүгээ эрьенгээ, албанай болон наймаанай хэрэгээр Үдын острог хирэ болоод лэ ерэдэг байгаа.\n",
      "Отец знал, что сына изранили, перекочевал со своими стадами из Тугнуйских степей в долину Уды, поближе к острогу, частенько навещал его.\n",
      "\n",
      "[]\n",
      "Энээн тухайда өөрынгөө дүтын нүхэр Василий Булавинһаа бэшэ хэндэшье хэлэдэггүй бэлэй.             Теэд саг ошожол байна ха юм.\n",
      "Ни с кем, кроме Булавина, не делился он своими думами, никому больше не высказывал, что тревожило сердце.    А что мог сказать молодой Булавин, что мог посоветовать?    Надо было потолковать с отцом, но Бадан не решался, знал крутой отцовский нрав.    Да и вообще, как говорить с отцом о таком деле, ведь старик и раньше никогда не хотел слышать о Залме.\n",
      "\n",
      "[]\n",
      "Теэд саг ошожол байна ха юм.\n",
      "Надо было потолковать с отцом, но Бадан не решался, знал крутой отцовский нрав.    Да и вообще, как говорить с отцом о таком деле, ведь старик и раньше никогда не хотел слышать о Залме.\n",
      "\n",
      "[]\n",
      "Буряад уг гарбалтанай ортон хамнигадаар, өөһэд зуураашье химардагынь мүн хариин харатанай харшалдаг добтолдогынь юунһээшье үлүүгээр һанааень зобооно.\n",
      "С отцом разговаривал о другом — о частых распрях между хоринскими бурятами и тунгусами, о том, как избавиться от воровских разорительных набегов Туше-гуна.\n",
      "\n",
      "[]\n",
      "Арад зонойнгоо ажана амгалан һууха тухай үбгэн Тураахи дурдахадаа, сог зали орон, ута сагаан һахалаа эльбэсэгээн: «Үдэхэеэ болиһон мал һүрэг соогоо мүргэлдэдэг, өөдэлхэеэ болиһон айл бүлэ соогоо хэрэлдэдэг», — гэжэ ходо хэлэдэг һэн. Тиибэшье буряад уг гарбалтанай энхэ амгалан, эмхи журамтай һуухын тулада засаг түрэ, хүсэтэй харгалзагша хэрэгтэй гэжэ мэдэдэг һэн.\n",
      "Отец оживлялся, говорил: надо, чтобы буряты жили в дружбе между собой, надо жить в дружбе с тунгусами. Они наши соседи. И в стаде плохо, когда коровы бодаются, не жди приплода…\n",
      "\n",
      "[]\n",
      "— Бидэ буряадууд үсөөхэн, буурай арад гээшэбди, — гэжэ үбгэн үргэлжэлнэ. — Тиибэшье өөһэдын түүхэтэй байхабди.       Манай хори буряад зон урдань Балжан хатанай энжэ боложо, манжа-баргын газарһаа энэ нютаг уруу зөөжэ ерэһэн гэхэ.\n",
      "— Мы, буряты, маленький народ,―— вздохнул Туракай, — но мы не первый день живем на земле.    Отцы наши жили и прадеды. Когда-то очень давно, однако, мы жили в Барге, кочевали по степи Хуленбуира.    С нами была наша праматерь Бальжин-хатан. Ну, Бальжин-хатан вышла замуж за баргутского хун-тайджи, хоринцы последовали за ней, во владения ее мужа.\n",
      "\n",
      "[]\n",
      "Тиихэдэнь манжа-баргынхид хойноһоонь намнаһан, хүл мүрынь алдахуулһан, урдаһаань ортон хамнигад эритэ мэсээр угтажа, баһал зобооһон туляаһан юм.       Мүнөөшье хүрэтэр хойноһоомнай дахаашан, урдаһаамнай угтаашан хохидол ушаруулна.\n",
      "Баргуты и маньчжуры невзлюбили нашу праматерь, преследовали ее…    Хоринцы вместе с ней прибыли к кукульбинским синим хребтам, оттуда подались в эти вот привольные степи, — Туракай снова горестно вздохнул. — Здесь нас тоже не друзья встретили. Отец сидел, понурив голову. Бадан хотел расспросить, что было после, но не посмел.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'casered', 'nacc', 'posred']})]\n",
      "Энэ үедэ шинии эсэгэ томо боложо, намдаа хамһалсадаг болоо һэн.\n",
      "Но к этому времени мне помогал уже взрослый сын — твой отец, Дагба.\n",
      "\n",
      "[]\n",
      "Адуу моридоо шэмэтэй һайхан ногоотой ойн соорхой соогуур адуулдаг байгаабди.\n",
      "Мы с твоим отцом выбрали для коней хорошее пастбище в горах. Там была густая, сочная трава.\n",
      "\n",
      "[]\n",
      "— Теэд, хүбүүн, мориднай хадын модоной соорхойгоор бэлшэжэ, тобир тарган болобо гэжэ бидэшни дан эртүүр баярлаһан байбабди.\n",
      "— Ну вот, хубун, рано порадовались мы с твоим отцом, что наверстали упущенное, что кони стали гладкие да резвые.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'casered', 'nacc', 'posred']})]\n",
      "Адуу моридоо туужа, үргэн тала худар гаргаха ёһотой байгаа ха юмбибди. Халаг даа, эгээл эндэ шинии эсэгэ бидэ хоёр заһагдашагүй, тон муухай алдуу хэжэрхиһэн байнабди.\n",
      "Мне бы послушаться своего чутья да погнать коней в степь, ближе к улусу, но мы с твоим отцом как-то не сообразили.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'casered', 'nacc', 'posred']}), ('отец', 'эсэгэтэйшни', {'lex': ['эсэгэ'], 'gramm': ['S', 'comit', 'poss_2sg'], 'sem': ['отец'], 'flags': ['bua', 'nacc']})]\n",
      "Боро азаргамнай жабжаараа хөөһэ буран, хоёр улаан нюдэдынь зэрлигшэн носожо, байса шулуунай эрмэг дээрэ арайхан тогтожо байхадань, шинии эсэгэ азаргын хүзүүндэ һур аргамжа хаяжа бугуулидаад, тогтоохо гэжэ оролдожо байтарынь, азарга хойноһоо ябаһан адуу моридто шахагдажа, хабсагайн гүн руу эсэгэтэйшни хамта унаа һэн.\n",
      "Жеребец с налившимися кровью дикими глазами, вздыбленный, с пеною у рта, метался на краю пропасти. Твой отец, накинув ему на шею веревку, старался остановить его, но на жеребца напирали другие кони, и он, не выдержав натиска, рухнул в пропасть вместе с твоим отцом.\n",
      "\n",
      "[('отец', 'эсэгыешни', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss_2sg'], 'sem': ['отец'], 'flags': ['bua', 'nacc']})]\n",
      "Хабсагайн саанаһаа гэнтэ гаража ерэһэн энэ гал түймэр харгы дээрэхи хуурай мүшэр хагда дүргэжэрхёод лэ, саашаа талиин холодоод, аадарта сохюулаа һэн.    Һүүлдэнь эсэгыешни аяар доро, хабсагай шулуунай хаяаһаа олоо һэм.    Үхөөдшье хэбтэхэдээ һур аргамжаяа гартаа бүхөөр барижа, табингүй хэбтээ һэн. Үнэхөөр лэ зоригтой баатар хүбүүн байгаа.\n",
      "Пожар как внезапно налетел, так и ушел дальше. Разразился сильный ливень.    Отца твоего нашли глубоко в ущелье.    Он был настоящий мужчина. Не выпустил узды из рук даже мертвый.\n",
      "\n",
      "[('отец', 'эсэгын', {'lex': ['эсэгэ'], 'gramm': ['S', 'gen'], 'sem': ['отец'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc', 'posred']})]\n",
      "Шинии эсэгын, хүбүүнэймни үхэһэн хойно, уданшьегүй эжышни ябашоо һэн. Анханай муу бэетэй хүн байгаа.\n",
      "После смерти моего сына, а твоего отца остались у меня дочь, да ты с больной матерью.\n",
      "\n",
      "[('отец', 'эсэгымни', {'lex': ['эсэгэ'], 'gramm': ['S', 'gen', 'poss_1sg'], 'sem': ['отец'], 'flags': ['acomma', 'amark', 'bua', 'nacc']})]\n",
      "— Эхымни түлөө, эсэгымни түлөө, Ханда хээтэймни түлөө харюусаха сагшни ерэбэ!\n",
      "Отвечай за смерть моего отца! Отвечай за красавицу Ханду! Отвечай за смерть моей матери!\n",
      "\n",
      "[('отец', 'баабайнь', {'lex': ['баабай'], 'gramm': ['S', 'gen', 'poss_3', 'S', 'nom', 'poss_3'], 'sem': ['отец', 'папа'], 'flags': ['bua', 'casered', 'nacc', 'posred']}), ('отец', 'эсэгэдэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'dat'], 'sem': ['отец'], 'flags': ['bua', 'nacc']}), ('отец', 'эсэгэнь', {'lex': ['эсэгэ'], 'gramm': ['S', 'nom', 'poss_3'], 'sem': ['отец'], 'flags': ['bua', 'nacc']})]\n",
      "Һураһан юумэ һураар татагдахагүй гэдэгтэл Иван Иванович часайнгаа заахан хармаан худар эжэлэнгүй гараа хээд үзэнэ. Тэрэ час үбгэн баабайнь Иванай эсэгэдэ бэлэглэһэн байгаа. Тэрэнииень эсэгэнь хүбүүндээ дамжуулан бэлэглээ һэн.\n",
      "Иван Иванович то и дело засовывал руку в маленький кармашек, где недавно лежали часы — подарок отца.\n",
      "\n",
      "[('отец', 'Эсэгынгээ', {'lex': ['эсэгэ'], 'gramm': ['S', 'gen', 'poss'], 'sem': ['отец'], 'flags': ['bua', 'capital', 'first', 'nacc']})]\n",
      "— Эсэгынгээ үгэһэн бэлэг худалдажа болодог юм аал?\n",
      "— Ты же говорил, что тебе их подарил твой отец. Разве можно продавать подарок?\n",
      "\n",
      "[]\n",
      "Эсэгэшнишье юумэ хэлээгүй юм, байһаар ши һургаха болобо гүш, бү түргэдэ…\n",
      "Такого даже от отца твоего не слыхала. Смотри мне… Не спеши учить.\n",
      "\n",
      "[]\n",
      "— Дугар яагаа гээшэб?    Гүй гүйһөөр манайда ерэбэл.    Аба, шамай яба гэжэ ерэбэ ха, — гэжэ дуугарна.\n",
      "— Что это с Дугаром, — ни к кому не обращаясь, сказала вдруг Янжима.    — Смотрите, как бежит к нам, — и повернувшись к отцу, добавила:    — Наверное, за тобой торопится.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'casered', 'nacc', 'posred']})]\n",
      "Юундэ? — гэлдэжэ эхэ эсэгэ хоёрынь зэргэ асууна.\n",
      "Зачем? — в один голос спросили отец и мать.\n",
      "\n",
      "[]\n",
      "Янжама гаргаха гэдэг бурхан торхо хоёроошье мартажархиһан, багашуулай зангаар эжы абадаа эрхэлэн татажа байгаад, эдеэлнэ, хубсална, түхеэрнэ.\n",
      "Забыв про злосчастных бурханов, которых вчера собиралась выбросить из дому, девушка резвилась, точно маленькая, подбегая то к матери, то к отцу.\n",
      "\n",
      "[]\n",
      "Тиихэдэнь залуушуулай дунда байһан Янжама: — Бай… хэн гэнэ? Намайе дуудана гү? — гэжэ дуугараад, һуга харайн бодожо, отогой ойро ерээд: — Намайе хэн дуудааб? — гэнэ.\n",
      "Девушка услышала зов отца. Она быстро поднялась и направилась к шалашу. Это ты меня звал, отец?\n",
      "\n",
      "[]\n",
      "— Энэ болбол үнгэрһэн зунай үедэ Раднын хүбүүнэй бэшэһэн бэшэг, — гэжэ уншана: «Хүндэтэ аба, эжы ба Янжама эгэшэдээ амарые хүргэнэб.\n",
      "Слушайте! — и Базар читает письмо: «Дорогой отец, дорогая мама! Передаю привет моей сестре Янжиме.\n",
      "\n",
      "[]\n",
      "Радна Дулгар хоёр ехэхэн баяртайнууд, хүбүүнэйнгээ хоёр тээнь һуужа, урихан нюдөөр харан байжа, үрдилдэн яаран, бэе бэеынгээ үгые таһа дүүрэлсэн, бүхы байдалаа, зобоһон ядаһанаа дууһан һанан һанан хэлэнэд.\n",
      "Два года он не видел родителей и сейчас со счастливой улыбкой смотрел то на отца, то мать, расспрашивал как они живут, рассказывал о себе, интересовался своими друзьями, знакомыми, спрашивал о новостях в родном улусе.\n",
      "\n",
      "[('отец', 'Эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['bua', 'capital', 'casered', 'first', 'nacc', 'posred']})]\n",
      "Эсэгэ хүбүүн хоёр халажа, дуу таһаралтагүй хөөрэлдэнэ.\n",
      "А отец с сыном продолжали беседовать, и Дулгар, ласково глядя на Гарму, прислушивалась к каждому слову.\n",
      "\n",
      "[('отец', 'эсэгэ', {'lex': ['эсэгэ'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom'], 'sem': ['отец'], 'flags': ['acomma', 'amark', 'bua', 'nacc']})]\n",
      "— Зай, Гарма, ши һайн ябажа ерэбэ гүш? — гэжэ асуугаад, харюу хэлэхыень хүлеэнгүй, эсэгэ тээшээ эрьен хаража, — аба, шамайе энэ гэһээр суглаанда ерэ гэнэ, хүлеэжэ байна.\n",
      "– Отец, тебя просят сейчас же прийти на собрание, там уже ждут.\n",
      "\n",
      "[]\n",
      "Аба, шамда нэгэ дэгэлэй бүд шагнал үгэхэ гэжэ бэлэдхэжэ байна.\n",
      "Отец, тебя собираются премировать материей па халат-дэли.\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i in docs:\n",
    "    pairs = i[1]\n",
    "    for pair in pairs:\n",
    "        a = pair.find_rus_in_bua('отец')\n",
    "        b += a\n",
    "        print(a)\n",
    "        print(pair.text_bua)\n",
    "        print(pair.text_rus)\n",
    "        print()\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пары бур. и рус. предложений и вся сопутствующая информация возвращаются как список типов `Pair`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный текст хранится в атрибутах `text_bua` / `text_rus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эсэгынгээ хэрэгээр Үдын байшан ошоһон аад, орой гэртээ хүрэжэ ерээ һэм, — гэжэ Бадан мүн лэ илдамаар харюусаад, урдаһаань баһа нэнгэжэ, ургынгаа гуйба мүртөө шагтагалһан баруун гараараа морин дээрэһээ Залмые хүзүүдэн, даараһандаа улайхадаһан хасартань өөрынгөө хасар няаба.\n",
      "— Отец отправил в Удинский острог, вернулся поздно. Не сердись, если не острог, обязательно приехал бы.\n"
     ]
    }
   ],
   "source": [
    "print(f'{pair.text_bua}\\n{pair.text_rus}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами токены и их информация хранятся в `tokens_язык` и `infos_язык`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: Эсэгынгээ\n",
      "info: {'lex': ['эсэгэ'], 'gramm': ['S', 'gen', 'poss'], 'sem': ['отец'], 'flags': ['bua', 'capital', 'first', 'nacc', 'posred']}\n",
      "\n",
      "token: хэрэгээр\n",
      "info: {'lex': ['хэрэг'], 'gramm': ['S', 'ins'], 'sem': ['дело'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: Үдын\n",
      "info: {'lex': ['үдын', 'үдэ'], 'gramm': ['A', 'S', 'gen'], 'sem': ['поддень', 'полдневный', 'полуденный'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: байшан\n",
      "info: {'lex': ['байшан', 'байшаха'], 'gramm': ['S', 'nom', 'V', 'circumst', 'cvb'], 'sem': ['байха_очутиться_где-л', 'дом', 'изба'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: ошоһон\n",
      "info: {'lex': ['ошохо'], 'gramm': ['V', 'partcp', 'praet', '3p'], 'sem': ['идти_куда-л'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: аад\n",
      "info: {'lex': ['аад'], 'gramm': ['A'], 'sem': ['но'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc']}\n",
      "\n",
      "token: орой\n",
      "info: {'lex': ['орой', 'оройхо'], 'gramm': ['S', 'nom', 'V', 'imper', '2p', 'sg'], 'sem': ['вовсе', 'совсем'], 'flags': ['acomma', 'amark', 'bua', 'nacc']}\n",
      "\n",
      "token: гэртээ\n",
      "info: {'lex': ['гэр'], 'gramm': ['S', 'dat', 'poss'], 'sem': ['дом'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: хүрэжэ\n",
      "info: {'lex': ['хүрэхэ', 'хүрхэ'], 'gramm': ['V', 'cvb', 'simult1', 'V', 'cvb', 'simult1'], 'sem': ['в_сочет', 'застывать', 'остывать', 'охлаждать', 'стынуть'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: ерээ\n",
      "info: {'lex': ['ерэхэ'], 'gramm': ['V', 'partcp', '3p', 'nonpast'], 'sem': ['приезжать'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: һэм\n",
      "info: {'lex': ['һэм', 'һэ'], 'gramm': ['PART', 'S', 'nom', 'poss_1sg'], 'sem': [], 'flags': ['bcomma', 'bmark', 'bua', 'nacc']}\n",
      "\n",
      "token: гэжэ\n",
      "info: {'lex': ['гэхэ'], 'gramm': ['V', 'cvb', 'simult1'], 'sem': ['говорить'], 'flags': ['acomma', 'amark', 'bua', 'nacc']}\n",
      "\n",
      "token: Бадан\n",
      "info: {'lex': ['бадан'], 'gramm': ['S', 'nom'], 'sem': [], 'flags': ['bua', 'capital', 'nacc']}\n",
      "\n",
      "token: мүн\n",
      "info: {'lex': ['мүн'], 'gramm': ['A'], 'sem': ['действительный', 'истинный', 'настоящий'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: лэ\n",
      "info: {'lex': ['лэ'], 'gramm': ['nonlex'], 'sem': [], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: илдамаар\n",
      "info: {'lex': ['илдамаар'], 'gramm': ['ADV'], 'sem': ['ласково', 'приветливо'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: харюусаад\n",
      "info: {'lex': ['харюусаха'], 'gramm': ['V', 'anterior', 'cvb'], 'sem': ['быть_соответствии_чем-л', 'отвечать_чему-л'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc']}\n",
      "\n",
      "token: урдаһаань\n",
      "info: {'lex': ['урда'], 'gramm': ['S', 'abl', 'poss_3'], 'sem': ['юг'], 'flags': ['acomma', 'amark', 'bua', 'nacc']}\n",
      "\n",
      "token: баһа\n",
      "info: {'lex': ['баһа', 'баһаха'], 'gramm': ['ADV', 'V', 'imper', '2p', 'sg'], 'sem': ['ещё', 'издеваться', 'опять', 'также'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: нэнгэжэ\n",
      "info: {'lex': ['нэнгэхэ'], 'gramm': ['V', 'cvb', 'simult1'], 'sem': ['прислоняться_к_груди_матери'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc', 'posred']}\n",
      "\n",
      "token: ургынгаа\n",
      "info: {'lex': ['ургы', 'урга'], 'gramm': ['S', 'gen', 'poss', 'S', 'gen', 'poss'], 'sem': ['«урга»', 'подснежник', 'прострел_обл', 'шест_петлей'], 'flags': ['acomma', 'amark', 'bua', 'nacc']}\n",
      "\n",
      "token: гуйба\n",
      "info: {'lex': ['гуйба', 'гуйбаха', 'гуйха'], 'gramm': ['S', 'nom', 'V', 'imper', '2p', 'sg', 'V', 'praet', '3p', 'sg'], 'sem': ['качаться_из_стороны_в_сторону', 'колебаться', 'просить', 'упрашивать'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: мүртөө\n",
      "info: {'lex': ['мүртөө'], 'gramm': ['A'], 'sem': ['к_тому_же', 'при_этом'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: шагтагалһан\n",
      "info: {'lex': ['шагтагалха'], 'gramm': ['V', 'partcp', 'praet', '3p'], 'sem': ['нацеплять'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: баруун\n",
      "info: {'lex': ['баруун'], 'gramm': ['A'], 'sem': ['западный', 'правый'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: гараараа\n",
      "info: {'lex': ['гар'], 'gramm': ['S', 'ins', 'poss'], 'sem': ['рука', 'руки'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: морин\n",
      "info: {'lex': ['морин'], 'gramm': ['S', 'nom'], 'sem': ['конь', 'лошадь', 'мерин'], 'flags': ['bua', 'nacc', 'posred']}\n",
      "\n",
      "token: дээрэһээ\n",
      "info: {'lex': ['дээрэһээ'], 'gramm': ['ADV'], 'sem': [], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: Залмые\n",
      "info: {'lex': ['залмые'], 'gramm': ['nonlex'], 'sem': [], 'flags': ['bua', 'capital', 'nacc']}\n",
      "\n",
      "token: хүзүүдэн\n",
      "info: {'lex': ['хүзүүдэхэ'], 'gramm': ['V', 'circumst', 'cvb'], 'sem': ['обнимать'], 'flags': ['bcomma', 'bmark', 'bua', 'nacc']}\n",
      "\n",
      "token: даараһандаа\n",
      "info: {'lex': ['даараһандаа'], 'gramm': ['nonlex'], 'sem': [], 'flags': ['acomma', 'amark', 'bua', 'nacc']}\n",
      "\n",
      "token: улайхадаһан\n",
      "info: {'lex': ['улайхадаһан'], 'gramm': ['nonlex'], 'sem': [], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: хасартань\n",
      "info: {'lex': ['хасар'], 'gramm': ['S', 'dat', 'poss_3'], 'sem': ['щека', 'щёки'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: өөрынгөө\n",
      "info: {'lex': ['өөрынгөө'], 'gramm': ['nonlex'], 'sem': [], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: хасар\n",
      "info: {'lex': ['хасар'], 'gramm': ['S', 'nom'], 'sem': ['щека', 'щёки'], 'flags': ['bua', 'nacc']}\n",
      "\n",
      "token: няаба\n",
      "info: {'lex': ['няаха'], 'gramm': ['V', 'praet', '3p', 'sg'], 'sem': ['клеить', 'приклеивать'], 'flags': ['bdot', 'bmark', 'bua', 'last', 'nacc']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for token, info in zip(pair.tokens_bua, pair.infos_bua):\n",
    "    if info:\n",
    "        print(f'token: {token}\\ninfo: {info}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, поиск бурятского токена с определенным переводом на русский через метод `find_rus_in_bua`  \n",
    "Возвращается список всех соответствующих бурятских токенов и их разборов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем отца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('отец',\n",
       "  'Эсэгынгээ',\n",
       "  {'lex': ['эсэгэ'],\n",
       "   'gramm': ['S', 'gen', 'poss'],\n",
       "   'sem': ['отец'],\n",
       "   'flags': ['bua', 'capital', 'first', 'nacc', 'posred']})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair.find_rus_in_bua('отец')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем коня)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('конь',\n",
       "  'морин',\n",
       "  {'lex': ['морин'],\n",
       "   'gramm': ['S', 'nom'],\n",
       "   'sem': ['конь', 'лошадь', 'мерин'],\n",
       "   'flags': ['bua', 'nacc', 'posred']})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair.find_rus_in_bua('конь')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сложные случаи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть сложные случаи, когда словоформа соответсвует сразу нескольким леммам, при этом у нее соответвенно несколько вариантов грам. разбора и несолько значений, которые сложно соотнести. Пример: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ('я', 'бидэ', {'lex': ['бидэ', 'бидэхэ', 'би'], 'gramm': ['S', 'acc', 'poss', 'S', 'nom', 'V', 'imper', '2p', 'sg', 'S', 'dat'], 'sem': ['мы', 'путешествовать', 'странствовать', 'я'], 'flags': ['bua', 'nacc', 'posred']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут получается 3 леммы, 4 грам. разбора и \"4\" значения (по сути 3, потому что  'путешествовать' и 'странствовать' близкие). Не понятно, как делить. Чтобы избежать ошибок, я взяла случаи, когда словоформе соответвует одна лемма, чтобы точно быть уверенными в разборе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "* ходо = ['вы', 'насквозь', 'пере', 'с', 'также_соответствует_приставкам_про', 'через_что-л'], 'gramm': ['ADV'], 'ex': [183]\n",
    "(разные значения, вообще надо бы делить на sense1, sense2, но как тогда разделить примеры и грам инфу? в остальных случаях значения однотипны, поэтому они объединяются в одно значение)\n",
    "* мэдэхэ = ['знать', 'узнавать_о_чем-л'], 'gramm': ['V', 'partcp', 'fut', '3p', 'sg'] (вроде лемма, но форма указанна как не инф.)\n",
    "* гурбан = ['три', 'трое', 'тройка'], 'gramm': ['NUM', 'S', 'nom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
